# Projectdocumentation

## 22.12.2018

Setting up process of getting data from Homepage, open it,
count words and exclude special characters from counting process.

Following modules are used in this case:

from urllib import request                                                                                      

from collections import Counter                                                                                            
from nltk import word_tokenize

## 26.12.2018

First error occured here:
"Failed loading english.pickle with nltk.data.load"

solution found on stackoverflow for that problem:

1.
Got to a prompt Shell

2. 
Write the following Code:

import nltk.data
nltk.download()

Press 'Enter'

3.
The installation window appears.

Go to the 'Models' tab and select 'punkt'

from under the identifier column.

Then click 'Download' and it will install the necessary files.

Then it should work

## 27.12.2018

Reading pandas documentation

Installing finally the following libraries:

conda install -c anaconda nltk 
conda install -c anaconda nltk
conda install -c districtdatalabs yellowbrick
conda install -c conda-forge wordcloud
conda install -c anaconda numpy
conda install -c conda-forge matplotlib
conda install -c chen pycharm

## 13.02.2019

Creating a virtual environment and upload the first try in my own repository.

Following sites were very useful:
https://ipython.readthedocs.io/en/stable(install(kernel_install.html
https://uoa-eresearch.github.io/eresearch-cookbook/recipe/2014/11/20/conda/

