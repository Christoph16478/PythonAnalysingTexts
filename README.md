# final_project

It is a very tiny project on text analysation.

The setup is the following:

First of all, there is a text document read and opened from the Internet.

Than stopwords and special characters are removed from it.

Afterwards following analysation is processed:

    Wordcloud
    Histogram
    Occurency of Words in whole sentence
    Lexical dispersion plot
    Searching for specific words or sequence of characters occurin in these words

After execution, the output is already shown in the jupyter notebook itself.

Explication of the containing files:

## requirements.txt
If you want to use the code in that project, first of all you have to set up
a specific environment called "fenv".

For doing that please follwo the instructions in the "requirements.txt" file.

## program.ipynb
That is the main program. Simply open int in a jupyter notebook
Don not forget to change kernel to the specific environment mentioned above.

## documentation.txt
It is just a small documentation about how the creation process of the project

## stopwords_de.txt
## stopwords_en.txt
These are the list containing words which are not required for the analysation.

## program_debugging.ipynb
It is an exact copy of "program.ipynb". only difference is, that there is a
called "pixie_debugger" from a Company called pixiedust.

Link or the pixiedebugger is below:
https://www.analyticsvidhya.com/blog/2018/07/pixie-debugger-python-debugging-tool-jupyter-notebooks-data-scientist-must-use/)

it is to mention that there was only a try given to that debugger.


